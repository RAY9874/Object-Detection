# RCNN

在目标检测识别任务中，CNN已经能够很好的对给定的图片进行分类，但是其不能找到目标的位置，既输入的图片只可以包含一种物体。而在现实的检测任务中，通常是多个物体叠加、并列等形式出现在图片中，所以目标定位任务就变得十分重要，此时RCNN（Region-based-CNN）横空出世，解决了定位问题。

## 算法流程

（1）区域建议 Region Proposal

（2）CNN 特征提取

（3）分类与边界回归

![RCNN流程图](.\img\RCNN流程图.png)



## （1）区域建议 Region Proposal

区域建议Region Proposal是一种传统的区域提取方法，基于启发式的区域提取方法，用的方法是selective -search（原理稍后解释），查看现有的小区域，合并两个最有可能的区域，重复此步骤，直到图像合并为一个区域，最后输出候选区域。然后将根据建议提取的目标图像标准化，作为CNN的标准输入可以看作窗口通过滑动获得潜在的目标图像，在RCNN中一般Candidate选项为**1k~2k**个即可，之后再对网格进行特征提取或卷积操作，然后基于就建议提取的目标图像将其标准化为CNN的标准输入。

## （2）CNN 特征提取

输入到CNN中疯狂卷积，需要注意的是，这里对建议的区域进行了变换，将建议的区域变为固定大小的图片以适合CNN的输入。

## （3）分类与边界回归

### 分类

RCNN中使用SVM作为分类器，为每一种需要识别的物体训练一个分类器。

#### 回归

传入图片bounding-box的四个值，分别为Px, Py, Pw, Ph，为图片的中心点坐标，和宽和高，还有对应的正确的框（Gx, Gy, Gw, Gh）





## Selective Search

selective search 算法原理图如下：

![selective-search](.\img\selective-search.png)

step0：生成区域集R，具体参见论文[《Efficient Graph-Based Image Segmentation》](http://blog.csdn.net/guoyunfei20/article/details/78727972)

step1：计算区域集R里每个相邻区域的相似度S={s1,s2,…} ,论文考虑了颜色、纹理、尺寸和空间交叠这4种相似度。

step2：找出相似度最高的两个区域，将其合并为新集，添加进R 

step3：从S中移除所有与step2中有关的子集 

step4：计算新集与所有子集的相似度 

step5：跳至step2，直至S为空



## 为什么选用SVM而不是softmax

引用 [知乎-张小凡](https://www.zhihu.com/question/54117650/answer/490424510) 的回答：

训练SVM分类器。对每个类都训练一个分类器，这时大于IOU大于0.7认为是正样本，小于0.3认为是负样本。其实之前步骤2)中阈值也是0.3，后来调试为0.5，因为这样可以**增加正样本数量防止过拟合**。如果采用有softmax的神经网络直接分类，将**阈值设定为0.5的话将导致分类得到的正样本位置并不准确**。所以在训练SVM分类器的时候阈值是0.7/0.3，保证了定位的准确度。采取hard negative mining 方法(初始时用所有样本训练，但是这样负样本可能远多于正样本，经过一轮训练后将score最高即最容易被误判的负样本加入新的负样本训练集，进行训练，重复以上步骤至达到停止条件比如分类器性能不再提升)，使得SVM适用于小样本训练，在样本不平衡时依然可以做到不会发生过拟合。





